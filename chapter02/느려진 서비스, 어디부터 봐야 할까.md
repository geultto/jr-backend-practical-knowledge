# 2장
## 느려진 서비스, 어디부터 봐야 할까

## [목차]
- [처리량과 응답 시간](#성능-문제의-정의-및-주요-지표)
- [병목 지점과 확장](#서버-성능-개선의-기초-병복-지점-파악)
- [DB 커넥션 풀](#db-커넥션-풀db-connection-pool)
- [서버 캐시](#서버-캐시-server-cache의-활용)
- [정적 자원과 캐시/CDN](#정적-자원-최적화-브라우저-캐시-및-cdn)
- [대기 처리](#순간적인-트래픽-폭증-처리-대기-처리-queueing)


# 성능 문제의 정의 및 주요 지표
주요 내용 : 사용자들이 체감하는 성능 저하의 현상과 서버 성능을 평가하는 두 가지 핵심 지료를 설명

앱을 실행했을 때 로딩 이미지가 오래 표시되거나 요금 정보를 조회하는데 10초 이상 걸린다면, 흔히 성능이 나쁘다고 말합니다.
성능 저하 시 가장 눈에 띄는 현상은 결과가 늦게 표시되는 것이고, 때로는 너무 오래 걸려서 타임아웃 에러가 발생하기도 합니다.
사용자는 동작하기까지 걸린 시간으로 성능을 판단하지만, 실제로는 네트워크 속도, 디스크 속도, 메모리 크기 등 다양한 지표가 관련되어 있습니다.
이 다양한 지표중 서버 성능과 관련된 가증 중요한 두 가지 지표는 바로 응답시간과 처리량입니다.

# 응답시간 (Response Time) 상세

주요 내용 : 응답시간의 정의, 구성 요소, 그리고 사업적 중요성을 설명

**응답시간**은 사용자의 요청을 처리하는 데 걸리는 시간을 의미합니다. 성능 측정 도구에서는 주로 response time으로 표시됩니다.<br>

응답시간은 크게 클라이언트가 서버에 연결하고 데이터를 전송하는 과정, 서버가 로직을 실행하는 서버 실행 과정, 그리고 서버가 클라이언트로 응답 데이터를 전송하는 과정으로 구성됩니다.<br>
서버 개발자들은 주로 서버 실행 시간에 집중하여 확인하며, 이 시간은 로직 수행, DB 연동(SQL 실행), 외부 API 연동, 그리고 응답 데이터 생성(전송) 등의 요소를 포함합니다. 
특히 DB 연동과 외부 API연동이 서버 처리 시간에 큰 비중을 차지합니다(경험상 DB 연동이 전체 실행 시간의 70~80% 이상을 차지할 수 있음)
응답 시간은 사업에 미치는 영향이 매우 큰데, 예를 들어 아마존은 응답 시간이 100ms 증가할 때마다 매출이 1% 감소한다는 통계를 발표한 바 있습니다

# 처리량 (Throughput) 및 TPS 

주요 내용 : 처리량의 정의, TPS, 그리고 최대 TPS 초과 시 발생하는 현상을 설명

**처리량**은 단위 시간당 시스템이 처리하는 작업량을 의미하는, 보통 TPS(초당 트랜잭션 수 ) 또는 RPS로 나타냅니다.
TPS 는 초당 트랜잭션 수 (Transaction per second)의 약자입니다. 최대 TPS는 시스템이 처리할 수 있는 최대 요청 수를 의미합니다.
만약 동시에 들어오는 요청 수가 최대 TPS를 초과하게 되면, 서버는 초과한 요청들을 나중에 처리합니다.
이 경우, 사용자 입장에서는 대기 시간이 발생하여 응답 시간이 증가하는 문제가 발생합니다. 응답시간의 증가는 결국 사용자 이탈로 이어질 수 있으므로, 
TPS 높이려면 서버가 동시에 처리할 수 있는 수를 늘리거나, 요청 처리 시간 자체를 줄여야합니다.

# 서버 성능 개선의 기초 병복 지점 파악

주요 내용 : 성능 문제의 원인과 개선을 위한 측정의 중요성, 그리고 병목 지점 찾는 방법을 설명

성능 문제는 주로 트래픽이 증가하면서 시스템이 수용할 수 있는 최대 TPS 를 초과하는 트래픽이 유입될 때 발생합니다.

성능을 개선하기 위해서는 막연히 시도하기보다는, 먼저 현재 서버의 TPS와 응답 시간을 측정하여 목표를 설정하고 효과적인 개선안을 도출해야 합니다. 

TPS 높이려면 우선 성능 문제가 발생하는 **병목 지점**을 찾는 것이 필수적입니다. 
문제 지점을 찾는 가장 간단한 방법은 처리 시간이 오래 걸리는 작업을 식별하는 것입니다.
대부분의 모니터링 도구(스카우터, 핀포인트, 뉴렐릭 등)는 실행 시간 추적 기능을 제공하므로, 이를 성능 문제는 주로 **DB 연동** 이나 **외부 API 연동** 과정에서 발생합니다.

<br>
* 외부 API 연동시, DB 커넥션 타임아웃으로 실패처리지만, 외부 API에서는 성공 처리를 하였다면 어떻게 해결을 해야될까?
    
- 도메인에 맞는 처리가 필요하다. 
- [분산 시스템에서 이중 결제를 방지하는 방법은 무엇일까요? ](https://mayanksharmasharma77.substack.com/p/how-to-avoid-double-payments-in-distributed)
- [멱등성을 통해 신뢰할 수 있는 결제 시스템 보장](https://dev.to/budiwidhiyanto/ensuring-reliable-payment-systems-with-idempotency-2d0l)

# 수직 확장(Scale-up)과 수평 확장(Scale-out)

주요 내용: 두 가지 확장 방식의 정의, 장단점, 그리고 적용 시 유의사항


* 들어가기 앞서,서버 확징이란 무엇이고 왜 중요한가?
-   '서버 확장' 이란 간단히 말해 **증가하는 사용자 수요를 감당하기 위해 시스템의 처리 용량을 늘리는 모든 과정**을 의미합니다.

그래서 서버 확장이 왜 중요한데?

그 이유는 명확하다.

- 사용자 경험 및 만족도 느린 로딩 시간과 서버 충돌을 방지하여 방문자가 불편함 없이 서비스를 이용하게 하고, 만족한 사용자가 다시 찾아오도록 만듭니다.
- 비즈니스 성장과 안정성 성능 저하 없이 더 많은 트래픽을 처리할 수 있다는 것은 곧 더 많은 고객을 유치하고 비즈니스를 안정적으로 성장시킬 수 있다는 의미입니다.
- 비용 효율성 및 연속성 인프라를 효율적으로 운영하여 불필요한 비용을 줄이고, 예기치 않은 장애로 인한 비즈니스 중단을 막아 연속성을 확보합니다.


간략한 수직 확장과 수평 확장의 설명
- 수직 확장은 CPU/메모리 증가로 급한 성능 문제를 빠르게 해결하지만 비용이 크고 한계가 있다.
- 수평 확장은 서버 추가로 TPS를 높이되, 로드 밸런서가 필수이며 DB/외부 API 병목 시 악화될 수 있다

## 상세한 내용 

수평적 확장 (Scale-out): **팀원을 늘리는 방법**<br>
수평적 확장은 기존 시스템에 더 많은 서버를 추가하여 일을 나누어 처리하는 방식입니다. 마치 한 명이 하던 일을 여러 명의 팀원을 새로 영입해 나누어 처리하는 것과 같습니다. 이렇게 여러 컴퓨터에 부하를 효과적으로 분산시켜 전체 시스템의 처리 용량을 늘리는 것이 핵심입니다.
<br>
## 수평적 확장의 핵심 장점
    • 높은 안정성 (고가용성) 가장 큰 장점은 '이중화(Redundancy)'를 통해 높은 안정성을 확보할 수 있다는 것입니다. 만약 서버 한 대에 문제가 생겨도, 나머지 다른 서버들이 그 일을 대신 처리해주기 때문에 웹사이트가 멈추지 않습니다. 이는 마치 팀원 중 한 명이 아파서 출근하지 못해도 다른 팀원들이 그 업무를 나눠서 처리하면 프로젝트는 중단되지 않는 것과 같은 원리입니다.
    • 유연한 확장성 필요할 때마다 큰 서비스 중단 없이 새로운 서버를 쉽게 추가할 수 있습니다. 이러한 유연성 덕분에 트래픽 예측이 어렵거나 빠른 성장이 예상되는 비즈니스에 매우 이상적인 방법입니다.
    • 장기적인 비용 효율성 처음 여러 대의 서버를 도입할 때는 비용이 들 수 있지만, 하나의 고성능 서버로 계속해서 업그레이드하는 것보다 장기적으로 더 경제적일 수 있습니다. 필요에 따라 서버를 추가하며 비용을 조절할 수 있기 때문입니다.
## 수평적 확장의 고려할 점
    • 관리의 복잡성 여러 서버가 마치 하나처럼 움직이게 하려면 정교한 관리가 필요합니다. 각 서버에 트래픽을 효율적으로 분배하는 **'로드 밸런싱(Load Balancing)'**과 서버 간의 데이터를 일치시키는 '데이터 동기화' 등 복잡한 기술이 요구되며, 이를 위해 숙련된 IT 인력이 필요할 수 있습니다.
    • 소프트웨어 호환성 모든 프로그램이 여러 서버에서 동시에 작동하도록 설계되지는 않았습니다. 사용하려는 소프트웨어나 애플리케이션이 이러한 분산 환경(수평적 확장)을 지원하는지 반드시 확인해야 합니다.
    • 네트워크 병목 현상 서버 개수가 늘어날수록 서버 간의 통신량도 증가합니다. 만약 서버 간 데이터를 주고받는 네트워크의 속도가 느리다면, 네트워크 자체가 시스템의 성능을 저하시키는 새로운 병목 지점이 될 수 있습니다.
    • 초기 설정 비용 여러 대의 서버와 관련 장비를 처음 도입할 때 상대적으로 높은 초기 투자 비용이 발생할 수 있습니다.

<br>
수평적 확장이 여러 명의 팀원을 늘리는 방식이라면, 완전히 반대되는 접근법도 있습니다. 바로 한 명의 팀원을 슈퍼히어로로 만드는 수직적 확장입니다.
<br><br>
수직적 확장 (Scale-up): 한 명의 슈퍼히어로를 만드는 방법 <br>
<br>
수직적 확장은 기존 서버 자체의 성능을 업그레이드하는 방식입니다. 여러 대의 서버를 추가하는 대신, 현재 사용 중인 서버의 CPU(중앙처리장치), RAM(메모리), 저장 공간(SSD/HDD) 등을 더 좋은 부품으로 교체하는 것입니다. 이는 마치 한 명의 팀원을 훈련시켜 더 강력한 슈퍼히어로로 만드는 것에 비유할 수 있습니다.

## 수직적 확장의 핵심 장점
    • 단순성 여러 서버를 조율할 필요 없이 단 하나의 서버만 관리하면 되므로 구조가 간단하고 운영이 편리합니다. 복잡한 네트워크 설정이나 데이터 동기화 문제에서 비교적 자유롭습니다.
    • 빠른 초기 구현 새로운 시스템을 구축하는 것이 아니라 기존 서버의 부품을 교체하거나 추가하는 방식이므로, 비교적 빠르게 성능을 향상시킬 수 있습니다.
    • 높은 소프트웨어 호환성 대부분의 소프트웨어는 기본적으로 단일 서버 환경에서 작동하도록 만들어졌기 때문에, 여러 서버를 사용하는 수평적 확장에 비해 호환성 문제를 겪을 가능성이 훨씬 적습니다.
## 수직적 확장의 고려할 점
    • 확장의 한계 컴퓨터 부품의 성능은 무한하지 않습니다. 업그레이드를 계속하다 보면 더 이상 성능을 높일 수 없는 물리적인 한계에 부딪히게 됩니다.
    • 단일 장애 지점 (Single Point of Failure) 가장 큰 약점입니다. 시스템 전체가 단 하나의 서버에 의존하기 때문에, 만약 그 서버에 문제가 발생하면 웹사이트 전체가 멈춰버리는 치명적인 위험이 있습니다.
    • 업그레이드 시 서비스 중단 (다운타임) 위험 초기 업그레이드는 빠를 수 있지만, 향후 더 큰 성능 향상을 위해 주요 부품을 교체할 때는 서버를 잠시 꺼야 하는 '다운타임'이 발생할 수 있습니다. 이는 곧 서비스 중단을 의미하므로 사용자 경험과 비즈니스에 직접적인 타격을 줄 수 있습니다.
    • 높은 업그레이드 비용 고성능 부품은 매우 비쌉니다. 성능을 높이기 위해 업그레이드를 거듭할수록 기하급수적으로 비용 부담이 커질 수 있습니다.
   
두 방법의 차이점을 한눈에 비교해보고 어떤 상황에 어떤 방법을 선택해야 할지 알아보자

| 특징          | 수평적 확장 (Scale-out)                  | 수직적 확장 (Scale-up)                  |
|---------------|-----------------------------------------|----------------------------------------|
| **핵심 개념** | 서버 개수를 늘려 부하를 분산           | 기존 서버의 성능을 강화 (CPU/메모리 증가) |
| **비유**      | 계산대를 여러 개 추가하는 것            | 계산원 한 명을 더 빠르게 만드는 것    |
| **주요 장점** | 높은 안정성, 유연한 확장, 장애 격리    | 단순함, 빠른 초기 구현                 |
| **주요 단점** | 관리 복잡, 네트워크 병목 가능성, 로드밸런서 필요 | 확장의 한계, 단일 장애 지점, 다운타임 위험 |
| **적합한 상황** | 빠르고 지속적인 트래픽 증가 예상 시   | 트래픽 예측 가능, 단순성 우선 시      |

어떠한것들이 더 맞을까?

'수평적 확장'과 '수직적 확장' 중 어느 것이 더 좋다고 단정할 수는 없습니다. 어떤 방법을 선택할지는 현재 상황과 미래 계획에 따라 달라집니다. 결정을 내릴 때 고려해야 할 핵심 요소는 다음과 같습니다.
1. 트래픽 패턴과 성장 예측 블랙 프라이데이 세일처럼 갑작스러운 트래픽 급증이 잦거나, 앞으로 비즈니스가 빠르게 성장할 것으로 예상된다면 서버를 유연하게 추가할 수 있는 수평적 확장이 유리합니다. 반면, 트래픽이 꾸준하고 예측 가능하다면 수직적 확장으로 시작하는 것이 더 간단한 방법일 수 있습니다.
2. 예산과 비용 초기 투자 비용과 장기적인 유지보수 비용을 함께 고려해야 합니다. 수평적 확장은 초기 비용이 높지만 장기적으로는 더 효율적일 수 있고, 수직적 확장은 초기 비용은 낮지만 업그레이드를 할수록 비용이 크게 증가할 수 있습니다.
3. 기술 전문성과 관리 복잡성 우리 팀이 여러 서버를 효율적으로 관리하고 운영할 수 있는 기술력을 갖추었는지 평가해야 합니다. 복잡한 시스템 관리가 부담스럽다면 수직적 확장이, 충분한 기술 전문성을 갖추었다면 수평적 확장이 더 나은 선택일 수 있습니다.

**클라우드 시대의 확장으로 더 쉽고 유연하게 대처가 가능합니다.**

AWS, Azure, GCP와 같은 클라우드 서비스 덕분에 서버 확장의 문턱이 낮아졌습니다. 
클라우드 환경에서는 클릭 몇번으로 서버(인스턴스)의 사양을 높이는 수직적 확장을 쉽게 할 수 있고, 트래픽 양에 따라 자동으로 서버 개수를 늘리고 줄이는 '오토 스케일링(Auto-scaling)' 기능으로 수평적 확장을 매유 효율적으로 구현할 수 있습니다.
덕분에 과거보다 훨씬 적은 비용과 노력으로 유연한 확장 전략을 구사할 수 있게 되었습니다.

궁극적으로 현대적인 시스템은 '하나만 선택' 하는 것이 아니라, 두가지 장점을 모두 취하는 **하이브리드(Hybrid) 접근 방식** 을 사용합니다.
예를 들어, 데이터의 일관성이 중요한 핵심 데이터 베이스 서버는 수직적으로 확장하여 강력한 단일 성능을 유지하고, 
외부 사용자의 요청을 처리하는 웹 애플리케이션 서버는 수평적으로 확장하여 트래픽 변화에 유연하게 대응하는 식입니다.

결론 :

웹사이트와 서비스가 성장함에 따라 서버 확장은 선택이 아닌 필수입니다.

 - 수평적 확장은 여러 서버를 추가하여 안정성과 유연성을 극대화하는 방법입니다.
 - 수직적 확장은 기존 서버를 강화하여 단순하고 빠르게 성능을 높이는 방법입니다.
<br>
어떤 방법이 절대적으로 뛰어난 것은 없습니다. 중요한 것은 자신의 서비스 특성, 성장 가능성, 그리고 가용 예산을 종합적으로 고려하여 가장 적합한 확장 전략을 선택하고 준비하는 것입니다. 성장을 위한 현명한 준비는 성공적인 온라인 비즈니스로 나아가는 튼튼한 첫걸음이 될 것입니다.


# DB 커넥션 풀(DB Connection Pool)

주요 내용 : 커넥션 풀의 필요성, 원리, 그리고 중요한 설정인 크기와 대기 시간에 대한 설명

* 핵심 : DB 커넥션 풀은 연결 생성/해제 오버헤드를 줄여 성능을 높이지만, 잘못된 설정은 DB 과부하나 대기 지연을 유발한다

DB를 사용할 때 네트워크 연결 생성 및 종료에 걸리는 시간은 전체 응답 시간의 상당 부분을 차지할 수 있어 처리량 저하를 유발합니다. 
이러한 문제를 피하기 위해 DB 커넥션 풀을 사용합니다. 
커넥션 풀은 DB에 연결된 커넥션을 미리 생성해서 보관하며, 필요한 경우 풀에서 커넥션을 가져와 사용하고 작업이 끝나면 반환하는 방식으로 응답시간을 줄입니다.
커넥션 풀 설정 중 가장 중요한 것은 커넥션 풀 크기이다. 이 크기는 전체 응답시간과 TPS를 고려하여 지정해야 합니다. 또한, 커넥션 대기 시간을 설정할 수 있는데, 
이는 풀에 커넥션이 없을 때 기다릴 수 있는 최대 시간을 의미합니다. 응답 시간이 중요한 서비스의 경우, 대기 시간을 짧게 설정하여 (0.5초에서 3초 이내 권장), 요청 취소 후 재요청으로 인해 동시 트래픽이 급증하는 상황을 방지하고 서버 부하를 안정적으로 유지할 수 있습니다

핵심 설정 파라미터

| 설정 항목   | 권장값 기준               | 목적 및 주의점(잘못 설정 시 문제점 포함)   |
|---------|----------------------|----------------------------|
| **maximumPoolSize** | CPU 코어 × 2 (10~50)   | 풀이 가질 수 있는 최대 연결 수. 너무 크면 DB에 과부하를 주고, 너무 작으면 요청 처리 지연이 발생합니다. |
| **connectionTimeout**  | 30초                  | 풀에서 연결을 얻기까지 대기하는 최대 시간. 너무 짧으면 정상적인 상황에서도 연결 실패가 잦아질 수 있습니다.       |
| **idleTimeout** | 10분                  | 사용되지 않는 유휴(Idle) 연결을 풀에서 제거하기까지 대기하는 시간. 유휴 연결을 정리하여 DB 리소스를 효율적으로 관리합니다.              |
| **maxLifetime**  | 관30분                 | 연결이 풀에서 살아있을 수 있는 최대 시간. DB나 네트워크 방화벽의 세션 타임아웃(예: wait_timeout)보다 짧게 설정하여, 이미 끊어진 '죽은' 연결을 애플리케이션이 사용하는 것을 방지합니다.  |


성능 테스트에 대한 가장 좋은 방안은?

최적의 성능을 내기 위해 꼭 기억해야 할 4가지 실천 방안은 다음과 같습니다.
1. 공식을 맹신하지 마세요: 풀 크기는 신중하게 계산하기 일반적으로 (CPU 코어 × 2) 공식을 기본 출발점으로 삼습니다. 하지만 애플리케이션의 작업이 디스크 I/O를 많이 사용한다면 이 처리량까지 고려하여 풀 크기를 조절해야 합니다. 참고로 Spring Boot의 기본 커넥션 풀인 HikariCP는 고정된 크기(fixed-size)의 풀을 사용하는 것을 권장합니다. 또한, MySQL의 기본 커넥션 제한이 151개인 것처럼 데이터베이스 자체의 최대 연결 수 제한도 반드시 확인해야 합니다.
2. 지표를 보고 판단하세요: 주기적인 모니터링은 필수 최적의 설정 값을 찾기 위해서는 지속적인 모니터링이 필수적입니다. 현재 사용 중인 활성(Active) 연결과 대기(Idle) 중인 연결의 비율, 풀에서 연결을 얻기까지 걸리는 대기 시간 등의 지표와 더불어 연결 누수(leak) 여부를 꾸준히 확인해야 합니다. 이를 위해 HikariCP가 제공하는 메트릭 기능을 활성화하여 주기적으로 로그를 분석하는 것이 중요합니다.
3. 고부하 환경에서는 풀 분리 고려하기 핀테크 서비스와 같이 매우 높은 부하가 발생하는 시스템에서는 단일 커넥션 풀만으로는 한계가 있을 수 있습니다. 이런 경우, 풀의 크기를 동적으로 조정하거나, 데이터 조회(Read) 작업을 위한 풀과 데이터 변경(Write) 작업을 위한 풀을 별도로 분리하여 운영하는 전략이 부하를 분산시키고 안정성을 높이는 데 효과적일 수 있습니다.
4. 유효하지 않은 연결은 사전에 차단하기 네트워크 문제 등으로 유효하지 않은 연결을 풀에서 가져와 사용하면 장애가 발생합니다. testOnBorrow와 같은 연결 검증 옵션을 활성화하여 풀에서 연결을 빌려올 때마다 유효성을 검사하는 것이 안정성을 크게 높입니다.



잘못된 설정의 두 가지 위험

커넥션 풀은 강력한 만큼, 설정 값을 잘못 지정하면 오히려 성능을 저하시키거나 시스템 전체에 장애를 일으킬 수 있습니다. 특히 다음 두 가지 위험에 유의해야 합니다.

- DB 과부하 풀의 최대 연결 개수(maximumPoolSize)를 너무 크게 설정하면, 수많은 연결이 동시에 데이터베이스에 몰려 DB 자체에 심각한 부하를 줄 수 있습니다. 이는 결국 DB 성능 저하로 이어져 애플리케이션 전체의 응답 속도를 떨어뜨립니다.
- 대기 지연 증가 반대로 풀의 최대 연결 개수를 너무 작게 설정하면, 모든 연결이 사용 중일 때 새로운 요청은 연결을 빌릴 수 없어 무작정 기다려야 합니다. 이로 인해 풀이 고갈(Exhaustion)되는 현상이 발생하며, 실제 Spring Boot의 기본 커넥션 풀인 HikariCP 환경에서 풀 고갈로 인해 응답 시간이 5배 이상 급증하는 사례가 빈번하게 발생할 정도로 치명적인 성능 저하를 유발합니다.

이러한 위험을 피하려면, 커넥션 풀의 핵심 설정 값들이 어떤 역할을 하는지 정확히 이해하고 신중하게 설정하는 것이 무엇보다 중요합니다.

# 서버 캐시 (Server Cache)의 활용

주요 내용 : 캐시의 필요성, 작동 방식, 효율성 지표(적중률), 그리고 데이터 삭제 규칙 설명

DB 서버 확장은 비용이 많이 들고 실행 시간을 획기적으로 줄이기 어렵습니다. 따라서 응답 시간과 처리량을 개선하기 위해 캐시(Cache) 사용을 고려할 수 있습니다.

캐시는 DB보다 데이터를 읽는 속도가 빠르기 때문에 자주 조회되는 데이터를 캐시에 보관하면 응답 시간을 줄일 수 있습니다.

캐시의 전형적인 동작 방식은 요청된 값이 캐시에 존재하는지 먼저 확인하고, 없으면 DB에서 조회한 후 캐시에 저장하고 사용하는 방식입니다.

캐시의 효율성은 **적중률(Hit Rate)**로 판단하며, 적중률이 높을수록 응답 시간이 감소하고 처리량이 증가하며 DB 부하가 줄어듭니다.

캐시 데이터에 제한이 있을 경우, 새로운 데이터를 저장할 때 기존 데이터를 제거해야 하며, 이때 LRU(가장 오래 사용되지 않은 데이터 제거), LFU(가장 적게 사용된 데이터 유지), FIFO(먼저 추가된 데이터 먼저 삭제) 등의 규칙이 사용됩니다

 * 데이터베이스 확장은 왜 어려운가?
   분산 시스템에서 다음 세 가지를 동시에 모두 만족할 수 없다는 이론입니다. 즉 CAP 이론
   
   | 요소 | 의미 |
   | ---- | ----- | 
   |Consistency (일관성) | 모든 노드가 같은 데이터를 본다 |
   |Availability (가용성) | 항상 응답을 받을 수 있다 |
   |Partition Tolerance | (분할 내성)네트워크 단절에도 시스템이 동작한다 |

- 수직 확장 (Scale-Up)
  - 서버 성능을 높이는 방식입니다. 한계가 명확하고, 비용이 기하급수적으로 증가합니다.
- 수평 확장 (Scale-Out)
  - 서버를 여러 대로 늘리는 방식입니다. 여기서 CAP 문제가 발생합니다.

### 관계형 데이터베이스의 딜레마
- 관계형 DB는 **강한 일관성(C)**을 보장하도록 설계되었습니다. 트랜잭션, 외래키, ACID 속성 등이 그 예입니다.

- 수평 확장을 하면?

- 여러 노드 간 데이터 동기화 필요
- 일관성을 유지하려면 노드 간 통신 필수
- 통신 지연 → 성능 저하
- 네트워크 장애 시 → 일관성 vs 가용성 선택 강요

### 결국 **"일관성을 유지하면서 확장하기가 매우 어렵다"**는 결론에 도달합니다.

그래서 캐시가 필요하다

데이터베이스 확장이 어려우니, 읽기 부하를 캐시로 분산시키는 것입니다.
### 캐시의 CAP 관점

캐시는 가용성(A)과 성능을 선택한 시스템입니다. 일관성은 어느 정도 포기합니다. (최신 데이터가 아닐 수 있음)

이것이 가능한 이유는 대부분의 읽기 요청은 약간의 지연된 데이터를 허용할 수 있기 때문입니다.

`전체 요청 중 읽기: 80~90%
전체 요청 중 쓰기: 10~20%
→ 읽기만 캐시로 처리해도 DB 부하가 급격히 감소`

* 핀테크 적용 팁: 결제/잔액 조회는 지터 + 분산 락 조합으로 쇄도/핫키 동시 대응, null 캐싱으로 악의적 공격도 차단.

  | 문제                     | 원인                    | 해결책                                     |
  | ---------------------- | --------------------- | --------------------------------------- |
  | 1. 캐시 쇄도 (Stampede)    | 캐시 동시 만료 → DB 집중      | 지터(Jitter): 만료시간에 0~10초 랜덤 지연 추가        |
  | 2. 캐시 관통 (Penetration) | null 값 미캐싱 → 반복 DB 조회 | 널 오브젝트: '값 없음'도 캐싱 (블룸 필터 또는 특수값)       |
  | 3. 캐시 시스템 장애           | 캐시 다운 → DB 과부하        | 대체 작동(Failover): 핵심 기능만 DB 처리, 부가 기능 중단 |
  | 4. 핫키(Hotkey) 만료       | 인기 키 만료 → 동시 DB 조회    | 분산 락: Redis RedLock으로 단일 재생성 보장         |

# 로컬 캐시와 리모트 캐시 비교

주요 내용 : 로컬 캐시와 리모트 캐시의 정의, 장단점, 그리고 선택 기준 설명

서버 캐시는 로컬 캐시와 리모트 캐시 두 종류가 있습니다. 

로컬 캐시는 서버 프로세스와 동일한 메모리를 사용하여 캐시 데이터에 빠르게 접근할 수 있고 구조가 단순하지만, 저장할 수 있는 데이터 크기에 제한이 있고 서버 재시작 시 데이터가 모두 삭제되는 단점이 있습니다. 

리모트 캐시(예: 레디스)는 별도 프로세스를 사용하며 캐시 크기를 유연하게 확장할 수 있고 서버 재시작에도 데이터가 유지되어 캐시 효율이 높습니다. 

다만, 네트워크 통신이 필요하여 로컬 캐시보다 속도가 상대적으로 느리고 시스템 구조가 복잡해집니다. 

데이터 규모가 작고 변경 빈도가 매우 낮다면 로컬 캐시로 충분하며, 데이터 규모가 크거나 배포 빈도가 높은 서비스라면 리모트 캐시 사용을 적극적으로 고려해야 합니다

# 캐시 전략 : 사전 적재와 무효화

주요내용 : 순간 트래픽 대응을 위한 캐시 사전 적재와 데이터 무결성을 위한 캐시 무효화의 중요성 설명

트래픽이 순간적으로 급증하는 패턴을 보일 경우 (예: 푸시 알림 직후), 사용자의 개별 정보가 캐시에 없을 수 있어 캐시 적중률이 순간적으로 0%에 가까워질 수 있습니다. 

이를 방지하기 위해 **캐시 사전 적재(Preloading)**를 통해 미리 데이터를 캐시에 넣어두면, 트래픽이 몰릴 때도 캐시 적중률을 높여 응답 시간을 안정적으로 유지하고 DB 부하 집중을 방지할 수 있습니다. 

또한, 캐시 사용 시 유효하지 않은 데이터를 적절한 시점에 삭제하는 캐시 무효화에 신경 써야 합니다. 

가격 정보나 게시글 내용처럼 변경에 민감한 데이터는 원본이 바뀌는 즉시 캐시를 무효화해야 하며, 로컬 캐시 대신 다른 서버의 캐시를 변경하지 못하는 문제가 없는 리모트 캐시에 보관하는 것이 좋습니다


# 가비지 컬렉터(GC)와 메모리 관리

주요 내용 : GC가 응답시간에 미치는 영향과 이를 완화하기 위한 객체 생성 제한 및 스트림 활용 방법 설명

자바, Go 같은 언어의 **가비지 컬렉터(GC)**는 사용이 끝난 객체를 메모리에서 자동 반환하여 개발자의 부담을 줄여주지만, GC가 실행되는 동안 애플리케이션 실행이 일시 중단되는 'Stop-The-World' 현상이 발생하여 응답 시간에 영향을 줄 수 있습니다.

메모리 사용량과 생성된 객체 수가 많을수록 GC 실행 시간은 길어집니다. GC 영향을 줄이려면 JVM에 할당된 최대 힙 크기를 실제 사용 패턴에 맞게 조정하여 검사해야 할 미사용 객체의 개수를 줄여야 합니다.

또한, 한 번에 대량으로 객체를 생성하는 것을 피하기 위해 콘텐츠 조회 API에서 조회 범위를 제한해야 합니다. 

파일 다운로드 기능 구현 시에도 파일을 한 번에 메모리에 로딩하는 대신 스트림(Stream)을 활용하여 파일 처리 과정에서 필요한 메모리 크기를 최소화해야 합니다



# 응답 데이터 압축 (Compression)

주요 내용: 데이터 전송 시간에 영향을 미치는 요인과 데이터 압축을 통한 성능 및 비용 개선 효과 설명

응답시간에는 데이터 전송 시간이 포함되며, 이 전송 시간은 네트워크 속도와 전송 데이터 크기에 영향을 받습니다. 

서버는 사용자의 네트워크 속도를 제어할 수 없지만, 전송 데이터 크기는 제어할 수 있습니다. 

이때 사용할 수 있는 방법이 바로 응답 데이터를 압축하여 전송하는 것입니다. 

HTML, CSS, JSON과 같은 텍스트 형식의 응답을 gzip으로 압축하면 70% 이상 크기를 줄일 수 있으며, 데이터 전송 크기가 줄어든 만큼 응답시간도 빨라집니다. 

응답 데이터 압축은 응답시간 개선뿐만 아니라, 트래픽 자체가 비용으로 직결되는 클라우드 환경에서 비용 절감 효과도 가져오므로 적극 검토해야 합니다

# 정적 자원 최적화 (브라우저 캐시 및 CDN)

주요 내용: 정적 자원 관리의 중요성, 브라우저 캐시 활용, 그리고 CDN의 역할과 이점 설명

서버가 응답하는 자원은 결과가 바뀌는 동적 자원과 이미지, JS, CSS처럼 같은 데이터를 응답하는 정적 자원으로 나뉩니다. 

온라인 쇼핑몰 같은 경우 정적 자원이 전체 트래픽에서 상당한 비중을 차지합니다 (첫 페이지에서 이미지와 스크립트가 약 94%를 차지하는 사례도 있음). 

불필요한 트래픽 발생을 줄이기 위해 HTTP 프로토콜의 Cache-Control 헤더를 이용해 클라이언트가 응답 데이터를 일정 시간 동안 로컬 캐시(브라우저 캐시)에 보관하도록 설정할 수 있습니다. 

브라우저 캐시를 사용하면 서버 트래픽과 네트워크 전송 비용을 아낄 수 있습니다. 

또한, 동시 사용자가 많아 네트워크가 포화되는 문제를 해결하고 콘텐츠를 빠르고 효율적으로 전달하기 위해 **CDN(Content Delivery Network)**을 사용해야 합니다. 

CDN은 여러 지역에 서버를 두어 사용자가 지리적으로 가까운 서버에 연결해 콘텐츠를 다운로드하게 함으로써 응답 시간을 개선하고, 오리진 서버가 처리해야 할 트래픽을 크게 줄여줍니다.


### CDN 사용의 4가지 핵심 이점

CDN을 사용하면 다양한 효과를 얻을 수 있지만, 대부분의 사용자에게 가장 중요한 네 가지 핵심 이점은 바로 속도, 비용, 안정성, 보안입니다.

1. 속도: 웹사이트 로딩 시간 단축
CDN의 가장 큰 장점은 방문자에게 콘텐츠를 물리적으로 가장 가까운 서버에서 전달하여 페이지 로딩 시간을 획기적으로 줄여준다는 것입니다. 
사용자와 서버 간의 거리가 짧아질수록 데이터가 오가는 시간도 줄어들기 때문입니다. 
웹사이트 로딩 속도가 빨라지면 방문자가 답답함을 느껴 사이트를 떠나는 '이탈률'이 줄어들고, 사이트에 더 오래 머물게 되어 전반적인 사용자 경험이 크게 향상됩니다. 
다시 말해 웹사이트가 빨라지면 더 많은 방문자가 더 오래 머물게 됩니다.

2. 비용: 호스팅 대역폭 비용 절감
웹사이트 운영 비용에서 큰 비중을 차지하는 것 중 하나가 바로 '대역폭 비용'입니다. 
이는 원본 서버가 방문자에게 데이터를 전송할 때 발생하는 트래픽 요금입니다. 
CDN은 콘텐츠를 캐싱(임시 저장)하고 다양한 최적화 기술을 통해 원본 서버가 직접 처리해야 할 데이터의 양을 크게 줄여줍니다. 
원본 서버의 데이터 전송량이 줄어들면, 웹사이트 소유자가 지불해야 하는 호스팅 비용이 직접적으로 절감되는 경제적 이점을 얻을 수 있습니다.

3. 3.안정성: 콘텐츠 가용성 및 이중화 확보
만약 하나의 서버에만 의존하고 있다면, 갑작스러운 트래픽 증가나 하드웨어 고장 시 웹사이트 전체가 멈출 수 있습니다. 
CDN은 전 세계에 분산된 여러 서버를 사용하기 때문에 이러한 위험을 효과적으로 방지합니다. 
특정 서버에 문제가 생기거나 트래픽이 몰려도 다른 서버들이 즉시 트래픽을 나누어 처리함으로써 웹사이트가 중단되는 것을 막아줍니다. 
이는 단일 서버에 의존하는 것보다 훨씬 높은 안정성을 제공하여, 사용자들이 언제든지 문제없이 사이트에 접속할 수 있도록 보장합니다.

4. 4.보안: 웹사이트 보안 강화
CDN은 웹사이트를 외부 공격으로부터 보호하는 강력한 방패 역할을 합니다. 
악의적인 트래픽으로 서버를 마비시키는 DDoS(분산 서비스 거부) 공격을 분산된 서버들이 흡수하여 완화하고, 데이터 전송을 암호화하는 보안 인증(TLS/SSL)을 강화하는 기능을 제공합니다. 
이처럼 CDN은 웹사이트를 외부 위협으로부터 보호하는 추가적인 보안 계층 역할을 하여, 사용자와 웹사이트 소유자 모두에게 더 안전한 인터넷 환경을 제공합니다.


# 순간적인 트래픽 폭증 처리 대기 처리 (Queueing)

주요 내용: 콘서트 예매와 같은 순간 트래픽 폭증 상황에서 서버 증설의 문제점과 대기 처리 시스템의 합리성 설명

콘서트 예매처럼 짧은 시간 동안 트래픽이 폭증하는 상황이 발생할 수 있습니다.

이때 서버와 DB를 최대 트래픽에 맞춰 무작정 증설하는 것은, 전체 서비스 시간 중 1%도 되지 않는 짧은 시간을 위해 높은 고정 비용을 지불해야 하므로 부담이 큽니다.

이와 반대로, 시스템이 수용할 수 있는 수준의 트래픽만 받아들이고 나머지는 대기 처리하는 합리적인 접근 방식이 있습니다. 

사용자 대기 시스템을 적용하면 서버를 증설하지 않고도 서비스를 안정적으로 제공할 수 있으며, 사용자들이 불필요하게 새로고침을 반복하여 트래픽이 폭증하는 것도 방지할 수 있습니다. 

높은 부하로 인해 서비스 자체가 불능 상태가 되는 것보다는 대기하는 것이 사용자에게도 더 나은 경험이 됩니다. 

이러한 대기 제어는 비용 효율적이며 서버 안정성을 유지하는 데 큰 장점이 있습니다

참조 자료 : 

### DB Connection Pool

- https://chat2db.ai/resources/blog/database-connection-pooling

### 캐시

- [토스](https://toss.tech/article/25301)
- [카카오](https://tech.kakaopay.com/post/local-caching-in-distributed-systems/)

### CDN
- [CloudFlare](https://www.cloudflare.com/ko-kr/learning/cdn/what-is-a-cdn/)

### GC
- [오라클](https://www.javacodegeeks.com/2025/08/java-gc-performance-g1-vs-zgc-vs-shenandoah.html)
